{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-30T15:13:03.078258Z",
     "iopub.status.busy": "2020-11-30T15:13:03.077369Z",
     "iopub.status.idle": "2020-11-30T15:13:03.117174Z",
     "shell.execute_reply": "2020-11-30T15:13:03.118301Z"
    },
    "papermill": {
     "duration": 0.068843,
     "end_time": "2020-11-30T15:13:03.118513",
     "exception": false,
     "start_time": "2020-11-30T15:13:03.049670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/moastartscriptseeds/rs_3_3.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_3_10.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_8_17.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_4_23.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_model.png\n",
      "/kaggle/input/moastartscriptseeds/4l_6_27.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_0_19.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_7_20.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_1_25.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_0_28.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_8_3.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_3_12.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_5_28.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_8_21.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_3_6.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_5_23.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_7_32.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_4_32.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_4_28.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_2_15.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_6_4.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_8_20.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_3_26.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_0_18.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_1_27.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_3_19.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_6_31.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_0_15.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_2_10.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_9_4.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_0_31.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_5_30.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_0_25.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_0_14.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_8_30.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_0_7.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_9_28.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_9_23.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_9_7.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_6_22.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_2_20.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_4_10.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_3_18.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_2_9.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_9_9.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_5_3.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_9_8.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_3_32.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_1_6.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_3_31.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_3_29.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_1_4.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_0_29.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_8_18.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_4_5.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_5_24.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_8_5.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_7_21.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_6_16.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_0_30.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_1_15.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_5_33.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_1_29.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_5_7.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_3_20.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_1_13.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_4_1.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_4_19.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_model.png\n",
      "/kaggle/input/moastartscriptseeds/4l_9_22.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_7_3.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_9_14.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_6_34.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_9_5.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_6_33.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_6_20.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_3_22.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_0_6.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_8_7.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_6_14.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_0_26.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_9_25.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_7_23.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_5_11.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_2_8.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_5_35.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_3_16.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_3_2.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_9_19.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_6_2.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_2_11.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_1_2.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_8_4.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_2_31.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_0_17.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_8_24.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_3_24.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_7_31.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_0_8.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_4_8.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_1_35.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_8_16.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_6_12.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_9_17.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_9_2.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_9_15.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_7_26.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_4_29.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_0_5.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_4_7.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_8_27.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_4_9.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_7_9.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_7_8.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_8_14.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_8_11.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_8_31.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_2_7.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_4_24.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_2_13.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_3_28.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_7_2.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_6_21.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_5_19.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_7_28.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_2_4.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_4_30.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_5_10.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_0_11.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_2_28.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_9_27.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_6_3.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_4_18.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_4_11.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_3_15.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_3_7.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_8_19.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_5_22.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_0_21.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_7_4.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_6_10.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_6_28.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_3_5.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_6_8.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_1_12.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_9_11.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_2_21.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_6_11.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_1_1.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_4_33.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_2_25.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_6_25.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_6_19.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_3_13.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_8_1.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_3_8.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_0_20.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_9_13.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_9_24.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_1_31.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_5_9.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_2_6.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_3_4.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_7_11.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_4_21.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_0_23.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_6_26.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_5_26.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_7_24.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_4_31.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_7_29.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_2_12.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_9_21.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_0_22.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_0_33.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_1_5.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_7_14.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_9_35.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_5_20.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_7_22.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_4_12.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_6_1.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_4_25.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_1_17.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_6_17.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_6_24.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_0_24.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_1_30.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_1_20.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_5_18.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_0_12.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_7_13.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_7_19.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_1_11.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_1_9.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_3_11.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_6_30.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_8_12.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_1_21.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_6_35.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_5_16.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_5_27.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_5_5.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_0_1.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_2_1.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_6_29.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_3_34.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_4_6.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_4_2.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_3_9.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_9_12.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_7_30.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_5_25.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_7_6.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_9_6.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_3_1.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_2_34.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_2_24.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_0_32.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_5_34.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_1_19.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_9_10.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_2_17.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_0_16.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_4_3.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_4_22.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_6_23.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_1_16.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_5_2.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_8_23.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_5_14.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_2_27.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_5_6.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_0_27.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_8_15.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_1_33.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_7_27.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_2_18.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_6_15.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_1_8.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_4_20.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_8_32.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_6_6.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_4_35.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_3_33.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_5_8.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_2_30.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_2_33.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_8_2.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_1_22.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_9_1.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_8_28.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_1_14.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_8_34.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_5_29.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_1_18.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_1_28.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_4_34.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_2_2.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_5_21.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_5_32.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_2_14.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_4_17.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_0_4.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_8_29.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_8_35.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_9_34.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_3_21.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_4_16.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_1_7.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_2_19.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_5_4.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_6_32.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_0_35.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_7_17.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_5_13.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_1_23.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_3_17.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_0_9.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_2_32.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_3_27.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_4_15.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_9_3.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_9_26.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_4_4.h5\n",
      "/kaggle/input/moastartscriptseeds/submission.csv\n",
      "/kaggle/input/moastartscriptseeds/rs_6_5.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_7_18.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_2_3.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_0_3.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_7_33.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_2_22.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_8_25.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_6_7.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_5_1.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_1_3.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_2_23.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_3_30.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_0_2.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_3_14.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_9_30.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_1_26.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_2_5.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_4_27.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_7_1.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_9_32.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_8_33.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_4_13.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_8_22.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_7_5.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_7_12.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_5_15.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_2_35.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_8_13.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_9_18.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_6_13.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_4_26.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_8_10.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_model.png\n",
      "/kaggle/input/moastartscriptseeds/3l_5_17.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_8_9.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_5_31.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_9_29.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_7_10.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_1_32.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_model.png\n",
      "/kaggle/input/moastartscriptseeds/5l_9_31.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_7_16.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_2_16.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_1_10.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_1_24.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_6_9.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_8_8.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_9_16.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_7_35.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_0_10.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_9_20.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_0_34.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_3_25.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_7_25.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_9_33.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_2_26.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_8_6.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_7_15.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_0_13.h5\n",
      "/kaggle/input/moastartscriptseeds/4l_8_26.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_3_35.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_2_29.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_model.png\n",
      "/kaggle/input/moastartscriptseeds/4l_3_23.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_5_12.h5\n",
      "/kaggle/input/moastartscriptseeds/2l_4_14.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_1_34.h5\n",
      "/kaggle/input/moastartscriptseeds/rs_7_7.h5\n",
      "/kaggle/input/moastartscriptseeds/5l_7_34.h5\n",
      "/kaggle/input/moastartscriptseeds/3l_6_18.h5\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/LICENSE\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/README.md\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/setup.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/setup.cfg\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/.gitignore\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/.travis.yml\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/iterstrat/ml_stratifiers.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/iterstrat/__init__.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/tests/test_ml_stratifiers.py\n",
      "/kaggle/input/iterative-stratification/iterative-stratification-master/tests/__init__.py\n",
      "/kaggle/input/lish-moa/test_features.csv\n",
      "/kaggle/input/lish-moa/sample_submission.csv\n",
      "/kaggle/input/lish-moa/train_drug.csv\n",
      "/kaggle/input/lish-moa/train_features.csv\n",
      "/kaggle/input/lish-moa/train_targets_scored.csv\n",
      "/kaggle/input/lish-moa/train_targets_nonscored.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-30T15:13:03.179182Z",
     "iopub.status.busy": "2020-11-30T15:13:03.178587Z",
     "iopub.status.idle": "2020-11-30T15:13:03.182440Z",
     "shell.execute_reply": "2020-11-30T15:13:03.182912Z"
    },
    "papermill": {
     "duration": 0.032706,
     "end_time": "2020-11-30T15:13:03.183022",
     "exception": false,
     "start_time": "2020-11-30T15:13:03.150316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/iterative-stratification/iterative-stratification-master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T15:13:03.235306Z",
     "iopub.status.busy": "2020-11-30T15:13:03.234415Z",
     "iopub.status.idle": "2020-11-30T15:13:10.122395Z",
     "shell.execute_reply": "2020-11-30T15:13:10.120840Z"
    },
    "papermill": {
     "duration": 6.919196,
     "end_time": "2020-11-30T15:13:10.122512",
     "exception": false,
     "start_time": "2020-11-30T15:13:03.203316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.metrics import log_loss\n",
    "import random\n",
    "import os\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T15:13:10.170327Z",
     "iopub.status.busy": "2020-11-30T15:13:10.168337Z",
     "iopub.status.idle": "2020-11-30T15:13:10.171022Z",
     "shell.execute_reply": "2020-11-30T15:13:10.171510Z"
    },
    "papermill": {
     "duration": 0.028716,
     "end_time": "2020-11-30T15:13:10.171652",
     "exception": false,
     "start_time": "2020-11-30T15:13:10.142936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FOLDS = 10\n",
    "# Number of epochs to train each model\n",
    "EPOCHS = 80\n",
    "# Batch size\n",
    "BATCH_SIZE = 124\n",
    "# Learning rate\n",
    "LR = 0.001\n",
    "# Verbosity\n",
    "VERBOSE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T15:13:10.220890Z",
     "iopub.status.busy": "2020-11-30T15:13:10.218992Z",
     "iopub.status.idle": "2020-11-30T15:13:10.221687Z",
     "shell.execute_reply": "2020-11-30T15:13:10.222208Z"
    },
    "papermill": {
     "duration": 0.02859,
     "end_time": "2020-11-30T15:13:10.222336",
     "exception": false,
     "start_time": "2020-11-30T15:13:10.193746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to seed everything \n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T15:13:10.273344Z",
     "iopub.status.busy": "2020-11-30T15:13:10.271719Z",
     "iopub.status.idle": "2020-11-30T15:13:10.274162Z",
     "shell.execute_reply": "2020-11-30T15:13:10.274668Z"
    },
    "papermill": {
     "duration": 0.032097,
     "end_time": "2020-11-30T15:13:10.274786",
     "exception": false,
     "start_time": "2020-11-30T15:13:10.242689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to map an filter out control group \n",
    "def mapping_and_filter(train, train_targets, test):\n",
    "    cp_type = {'trt_cp': 0, 'ctl_vehicle': 1}\n",
    "    cp_dose = {'D1': 0, 'D2': 1}\n",
    "    for df in [train, test]:\n",
    "        df['cp_type'] = df['cp_type'].map(cp_type)\n",
    "        df['cp_dose'] = df['cp_dose'].map(cp_dose)\n",
    "    train_targets = train_targets[train['cp_type'] == 0].reset_index(drop=True)\n",
    "    train = train[train['cp_type'] == 0].reset_index(drop=True)\n",
    "    train_targets.drop(['sig_id'], inplace=True, axis=1)\n",
    "    return train, train_targets, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T15:13:10.326063Z",
     "iopub.status.busy": "2020-11-30T15:13:10.324206Z",
     "iopub.status.idle": "2020-11-30T15:13:10.326796Z",
     "shell.execute_reply": "2020-11-30T15:13:10.327300Z"
    },
    "papermill": {
     "duration": 0.031482,
     "end_time": "2020-11-30T15:13:10.327418",
     "exception": false,
     "start_time": "2020-11-30T15:13:10.295936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to scale our data \n",
    "def scaling(train, test):\n",
    "    features = train.columns[2:]\n",
    "    scaler = RobustScaler()\n",
    "    scaler.fit(pd.concat([train[features], test[features]], axis=0))\n",
    "    train[features] = scaler.transform(train[features])\n",
    "    test[features] = scaler.transform(test[features])\n",
    "    return train, test, features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T15:13:10.384547Z",
     "iopub.status.busy": "2020-11-30T15:13:10.383710Z",
     "iopub.status.idle": "2020-11-30T15:13:10.386856Z",
     "shell.execute_reply": "2020-11-30T15:13:10.387345Z"
    },
    "papermill": {
     "duration": 0.03883,
     "end_time": "2020-11-30T15:13:10.387471",
     "exception": false,
     "start_time": "2020-11-30T15:13:10.348641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to extract pca features \n",
    "def fe_pca(train, test, n_components_g=70, n_components_c=10, SEED=123):\n",
    "    \n",
    "    features_g = list(train.columns[4:776])\n",
    "    features_c = list(train.columns[776:876])\n",
    "    \n",
    "    def create_pca(train, test, features, kind='g', n_components=n_components_g):\n",
    "        train_ = train[features].copy()\n",
    "        test_ = test[features].copy()\n",
    "        data = pd.concat([train_, test_], axis=0)\n",
    "        pca = PCA(n_components=n_components, random_state=SEED)\n",
    "        data = pca.fit_transform(data)\n",
    "        columns = [f'pca_{kind}{i+1}' for i in range(n_components)]\n",
    "        data = pd.DataFrame(data, columns=columns)\n",
    "        train_ = data.iloc[:train.shape[0]]\n",
    "        test_ = data.iloc[train.shape[0]:].reset_index(drop=True)\n",
    "        train = pd.concat([train, train_], axis=1)\n",
    "        test = pd.concat([test, test_], axis=1)\n",
    "        return train, test \n",
    "    \n",
    "    train, test = create_pca(train, test, features_g, kind='g', n_components=n_components_g)\n",
    "    train, test = create_pca(train, test, features_c, kind='c', n_components=n_components_c)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T15:13:10.448786Z",
     "iopub.status.busy": "2020-11-30T15:13:10.446679Z",
     "iopub.status.idle": "2020-11-30T15:13:10.449512Z",
     "shell.execute_reply": "2020-11-30T15:13:10.450021Z"
    },
    "papermill": {
     "duration": 0.04035,
     "end_time": "2020-11-30T15:13:10.450172",
     "exception": false,
     "start_time": "2020-11-30T15:13:10.409822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to extract common stats features \n",
    "def fe_stats(train, test):\n",
    "    \n",
    "    features_g = list(train.columns[4:776])\n",
    "    features_c = list(train.columns[776:876])\n",
    "    \n",
    "    for df in [train, test]:\n",
    "        df['g_sum'] = df[features_g].sum(axis = 1)\n",
    "        df['g_mean'] = df[features_g].mean(axis = 1)\n",
    "        df['g_std'] = df[features_g].std(axis = 1)\n",
    "        df['g_kurt'] = df[features_g].kurtosis(axis = 1)\n",
    "        df['g_skew'] = df[features_g].skew(axis = 1)\n",
    "        df['c_sum'] = df[features_c].sum(axis = 1)\n",
    "        df['c_mean'] = df[features_c].mean(axis = 1)\n",
    "        df['c_std'] = df[features_c].std(axis = 1)\n",
    "        df['c_kurt'] = df[features_c].kurtosis(axis = 1)\n",
    "        df['c_skew'] = df[features_c].skew(axis = 1)\n",
    "        df['gc_sum'] = df[features_g + features_c].sum(axis = 1)\n",
    "        df['gc_mean'] = df[features_g + features_c].mean(axis = 1)\n",
    "        df['gc_std'] = df[features_g + features_c].std(axis = 1)\n",
    "        df['gc_kurt'] = df[features_g + features_c].kurtosis(axis = 1)\n",
    "        df['gc_skew'] = df[features_g + features_c].skew(axis = 1)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T15:13:10.501517Z",
     "iopub.status.busy": "2020-11-30T15:13:10.499538Z",
     "iopub.status.idle": "2020-11-30T15:13:10.502227Z",
     "shell.execute_reply": "2020-11-30T15:13:10.502684Z"
    },
    "papermill": {
     "duration": 0.030634,
     "end_time": "2020-11-30T15:13:10.502799",
     "exception": false,
     "start_time": "2020-11-30T15:13:10.472165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def c_squared(train, test):\n",
    "    \n",
    "    features_c = list(train.columns[776:876])\n",
    "    for df in [train, test]:\n",
    "        for feature in features_c:\n",
    "            df[f'{feature}_squared'] = df[feature] ** 2\n",
    "    return train, test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T15:13:10.558020Z",
     "iopub.status.busy": "2020-11-30T15:13:10.557230Z",
     "iopub.status.idle": "2020-11-30T15:13:10.559867Z",
     "shell.execute_reply": "2020-11-30T15:13:10.560406Z"
    },
    "papermill": {
     "duration": 0.034385,
     "end_time": "2020-11-30T15:13:10.560542",
     "exception": false,
     "start_time": "2020-11-30T15:13:10.526157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to calcualte the mean log loss of the targets including clipping \n",
    "def mean_log_loss(y_true, y_pred):\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    metrics = []\n",
    "    for target in range(206):\n",
    "        metrics.append(log_loss(y_true[:, target], y_pred[:, target], labels=[0, 1]))\n",
    "    return np.mean(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T15:13:10.631210Z",
     "iopub.status.busy": "2020-11-30T15:13:10.630233Z",
     "iopub.status.idle": "2020-11-30T15:13:10.633337Z",
     "shell.execute_reply": "2020-11-30T15:13:10.632645Z"
    },
    "papermill": {
     "duration": 0.048896,
     "end_time": "2020-11-30T15:13:10.633441",
     "exception": false,
     "start_time": "2020-11-30T15:13:10.584545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_residual_model(shape1, shape2):\n",
    "    input_1 = tf.keras.layers.Input(shape=(shape1))\n",
    "    input_2 = tf.keras.layers.Input(shape=(shape2))\n",
    "    \n",
    "    head_1 = tf.keras.layers.BatchNormalization()(input_1)\n",
    "    # original:0.2\n",
    "    head_1 = tf.keras.layers.Dropout(0.3)(head_1)\n",
    "    head_1 = tf.keras.layers.Dense(512, activation=\"elu\")(head_1)\n",
    "    head_1 = tf.keras.layers.BatchNormalization()(head_1)\n",
    "    input_3 = tf.keras.layers.Dense(256, activation='elu')(head_1)\n",
    "    \n",
    "    input_3_concat = tf.keras.layers.Concatenate()([input_2, input_3])\n",
    "    \n",
    "    head_2 = tf.keras.layers.BatchNormalization()(input_3_concat)\n",
    "    head_2 = tf.keras.layers.Dropout(0.3)(head_2)\n",
    "    head_2 = tf.keras.layers.Dense(512, \"relu\")(head_2)\n",
    "    head_2 = tf.keras.layers.BatchNormalization()(head_2)\n",
    "    head_2 = tf.keras.layers.Dense(512, \"elu\")(head_2)\n",
    "    head_2 = tf.keras.layers.BatchNormalization()(head_2)\n",
    "    head_2 = tf.keras.layers.Dense(256, \"relu\")(head_2)\n",
    "    head_2 = tf.keras.layers.BatchNormalization()(head_2)\n",
    "    input_4 = tf.keras.layers.Dense(256, \"elu\")(head_2)\n",
    "    \n",
    "    input_4_avg = tf.keras.layers.Average()([input_3, input_4])\n",
    "    \n",
    "    head_3 = tf.keras.layers.BatchNormalization()(input_4_avg)\n",
    "    head_3 = tf.keras.layers.Dense(256, kernel_initializer='lecun_normal', activation=\"selu\")(head_3)\n",
    "    head_3 = tf.keras.layers.BatchNormalization()(head_3)\n",
    "    head_3 = tf.keras.layers.Dense(206, kernel_initializer='lecun_normal', activation='selu')(head_3)\n",
    "    head_3 = tf.keras.layers.BatchNormalization()(head_3)\n",
    "    output = tf.keras.layers.Dense(206, activation=\"sigmoid\")(head_3)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[input_1, input_2], outputs=output)\n",
    "    opt = tf.optimizers.Adam(learning_rate=LR)\n",
    "    model.compile(optimizer=opt,\n",
    "                 loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.0015),\n",
    "                  metrics = tf.keras.metrics.BinaryCrossentropy()\n",
    "                 )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T15:13:10.688842Z",
     "iopub.status.busy": "2020-11-30T15:13:10.687959Z",
     "iopub.status.idle": "2020-11-30T15:13:10.700749Z",
     "shell.execute_reply": "2020-11-30T15:13:10.700170Z"
    },
    "papermill": {
     "duration": 0.044248,
     "end_time": "2020-11-30T15:13:10.700856",
     "exception": false,
     "start_time": "2020-11-30T15:13:10.656608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to create our 5 layer dnn model \n",
    "def create_five_layers_model(shape):\n",
    "    inp = tf.keras.layers.Input(shape=(shape))\n",
    "    x = tf.keras.layers.BatchNormalization()(inp)\n",
    "    # original: dropout: 0.4, here we all change them to be 0.3 \n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    x = tf.keras.layers.Dense(2560, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    x = tf.keras.layers.Dense(2048, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    # original: 1524\n",
    "    x = tf.keras.layers.Dense(1536, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    # original: 1012\n",
    "    x = tf.keras.layers.Dense(1024, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    # original: 780\n",
    "    x = tf.keras.layers.Dense(768, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    out = tf.keras.layers.Dense(206, activation = 'sigmoid')(x)\n",
    "    model = tf.keras.models.Model(inputs = inp, outputs = out)\n",
    "    opt = tf.optimizers.Adam(learning_rate = LR)\n",
    "    opt = tfa.optimizers.SWA(opt)\n",
    "    model.compile(optimizer = opt, \n",
    "                  loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.0020),\n",
    "                  metrics = tf.keras.metrics.BinaryCrossentropy())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T15:13:10.762484Z",
     "iopub.status.busy": "2020-11-30T15:13:10.761622Z",
     "iopub.status.idle": "2020-11-30T15:13:10.765105Z",
     "shell.execute_reply": "2020-11-30T15:13:10.764545Z"
    },
    "papermill": {
     "duration": 0.041082,
     "end_time": "2020-11-30T15:13:10.765226",
     "exception": false,
     "start_time": "2020-11-30T15:13:10.724144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to create our 4 layer dnn model\n",
    "def create_four_layers_model(shape):\n",
    "    inp = tf.keras.layers.Input(shape = (shape))\n",
    "    x = tf.keras.layers.BatchNormalization()(inp)\n",
    "    # original: dropout: 0.4, here we all change them to be 0.3\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    x = tf.keras.layers.Dense(2048, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    # original: 1524\n",
    "    x = tf.keras.layers.Dense(1536, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    # original: 1012\n",
    "    x = tf.keras.layers.Dense(1028, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    # original: 1012\n",
    "    x = tf.keras.layers.Dense(1028, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    out = tf.keras.layers.Dense(206, activation = 'sigmoid')(x)\n",
    "    model = tf.keras.models.Model(inputs = inp, outputs = out)\n",
    "    opt = tf.optimizers.Adam(learning_rate = LR)\n",
    "    model.compile(optimizer = opt, \n",
    "                  loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.0020),\n",
    "                  metrics = tf.keras.metrics.BinaryCrossentropy())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T15:13:10.824651Z",
     "iopub.status.busy": "2020-11-30T15:13:10.817116Z",
     "iopub.status.idle": "2020-11-30T15:13:10.827536Z",
     "shell.execute_reply": "2020-11-30T15:13:10.826946Z"
    },
    "papermill": {
     "duration": 0.040145,
     "end_time": "2020-11-30T15:13:10.827635",
     "exception": false,
     "start_time": "2020-11-30T15:13:10.787490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to create our 3 layer dnn model\n",
    "def create_three_layers_model(shape):\n",
    "    inp = tf.keras.layers.Input(shape = (shape))\n",
    "    x = tf.keras.layers.BatchNormalization()(inp)\n",
    "    x = tf.keras.layers.Dropout(0.4914099166744246)(x)\n",
    "    x = tfa.layers.WeightNormalization(tf.keras.layers.Dense(1159, activation = 'relu'))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.18817607797795838)(x)\n",
    "    x = tfa.layers.WeightNormalization(tf.keras.layers.Dense(960, activation = 'relu'))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.12542057776853896)(x)\n",
    "    x = tfa.layers.WeightNormalization(tf.keras.layers.Dense(1811, activation = 'relu'))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.20175242230280122)(x)\n",
    "    out = tfa.layers.WeightNormalization(tf.keras.layers.Dense(206, activation = 'sigmoid'))(x)\n",
    "    model = tf.keras.models.Model(inputs = inp, outputs = out)\n",
    "    opt = tf.optimizers.Adam(learning_rate = LR)\n",
    "    opt = tfa.optimizers.Lookahead(opt, sync_period = 10)\n",
    "    model.compile(optimizer = opt, \n",
    "                  loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.0015),\n",
    "                  metrics = tf.keras.metrics.BinaryCrossentropy())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T15:13:10.889108Z",
     "iopub.status.busy": "2020-11-30T15:13:10.888126Z",
     "iopub.status.idle": "2020-11-30T15:13:10.890972Z",
     "shell.execute_reply": "2020-11-30T15:13:10.890457Z"
    },
    "papermill": {
     "duration": 0.039851,
     "end_time": "2020-11-30T15:13:10.891086",
     "exception": false,
     "start_time": "2020-11-30T15:13:10.851235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to create our 2 layer dnn model\n",
    "def create_two_layers_model(shape):\n",
    "    inp = tf.keras.layers.Input(shape = (shape))\n",
    "    x = tf.keras.layers.BatchNormalization()(inp)\n",
    "    x = tf.keras.layers.Dropout(0.2688628097505064)(x)\n",
    "    x = tfa.layers.WeightNormalization(tf.keras.layers.Dense(1292, activation = 'relu'))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.4598218403250696)(x)\n",
    "    x = tfa.layers.WeightNormalization(tf.keras.layers.Dense(983, activation = 'relu'))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.4703144018483698)(x)\n",
    "    out = tfa.layers.WeightNormalization(tf.keras.layers.Dense(206, activation = 'sigmoid'))(x)\n",
    "    model = tf.keras.models.Model(inputs = inp, outputs = out)\n",
    "    opt = tf.optimizers.Adam(learning_rate = LR)\n",
    "    opt = tfa.optimizers.Lookahead(opt, sync_period = 10)\n",
    "    model.compile(optimizer = opt, \n",
    "                  loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.0015),\n",
    "                  metrics = tf.keras.metrics.BinaryCrossentropy())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T15:13:10.953127Z",
     "iopub.status.busy": "2020-11-30T15:13:10.952336Z",
     "iopub.status.idle": "2020-11-30T15:13:10.955320Z",
     "shell.execute_reply": "2020-11-30T15:13:10.954811Z"
    },
    "papermill": {
     "duration": 0.042536,
     "end_time": "2020-11-30T15:13:10.955438",
     "exception": false,
     "start_time": "2020-11-30T15:13:10.912902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to train our dnn \n",
    "def inference(train, test, train_targets, features, start_predictors, SEED=123, MODEL='3l', PATH='/kaggle/input/moastartscriptseeds'):\n",
    "    seed_everything(SEED)\n",
    "    oof_pred = np.zeros((train.shape[0], 206))\n",
    "    test_pred = np.zeros((test.shape[0], 206))\n",
    "    kfold_splitter = MultilabelStratifiedKFold(n_splits = FOLDS, random_state = SEED, shuffle = True)\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold_splitter.split(train_targets, train_targets)):\n",
    "        K.clear_session()\n",
    "        if MODEL == '5l':\n",
    "            model = create_five_layers_model(len(features))\n",
    "        elif MODEL == '4l':\n",
    "            model = create_four_layers_model(len(features))\n",
    "        elif MODEL == '3l':\n",
    "            model = create_three_layers_model(len(features))\n",
    "        elif MODEL == '2l':\n",
    "            model = create_two_layers_model(len(features))\n",
    "        elif MODEL == \"rs\":\n",
    "            model = create_residual_model(len(features), len(start_predictors))\n",
    "        \n",
    "\n",
    "        x_train, x_val = train[features].values[trn_ind], train[features].values[val_ind]\n",
    "        y_train, y_val = train_targets.values[trn_ind], train_targets.values[val_ind]\n",
    "        # restore best weights\n",
    "        model.load_weights(f'{PATH}/{MODEL}_{fold}_{SEED}.h5')\n",
    "        \n",
    "        if MODEL == 'rs':\n",
    "            x_train_, x_val_ = train[start_predictors].values[trn_ind], train[start_predictors].values[val_ind]\n",
    "            oof_pred[val_ind] = model.predict([x_val, x_val_])\n",
    "            test_pred += model.predict([test[features].values, test[start_predictors].values]) / FOLDS\n",
    "        else:\n",
    "            oof_pred[val_ind] = model.predict(x_val)\n",
    "            test_pred += model.predict(test[features].values) / FOLDS \n",
    "            \n",
    "    oof_score = mean_log_loss(train_targets.values, oof_pred)\n",
    "    print(f'Our out of folds mean log loss score is {oof_score}')\n",
    "    \n",
    "    return test_pred, oof_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T15:13:11.010972Z",
     "iopub.status.busy": "2020-11-30T15:13:11.010069Z",
     "iopub.status.idle": "2020-11-30T15:13:11.012873Z",
     "shell.execute_reply": "2020-11-30T15:13:11.012328Z"
    },
    "papermill": {
     "duration": 0.03504,
     "end_time": "2020-11-30T15:13:11.012977",
     "exception": false,
     "start_time": "2020-11-30T15:13:10.977937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to train out model with multiple seeds and average the predictions \n",
    "def run_multiple_seeds(train, test, train_targets, features, start_predictors, SEEDS=[123], MODEL='3l', PATH='/kaggle/input/moastartscriptseeds'):\n",
    "    \n",
    "    test_pred = []\n",
    "    oof_pred = []\n",
    "    \n",
    "    for SEED in SEEDS:\n",
    "        print(f'Using model {MODEL} with seed {SEED} for inference')\n",
    "        print(f'Trained with {len(features)} features')\n",
    "        test_pred_, oof_pred_ = inference(train, test, train_targets, features, start_predictors=start_predictors, SEED=SEED, MODEL=MODEL, PATH=PATH)\n",
    "        test_pred.append(test_pred_)\n",
    "        oof_pred.append(oof_pred_)\n",
    "        print('-'*50)\n",
    "        print('\\n')\n",
    "        \n",
    "    test_pred = np.average(test_pred, axis=0)\n",
    "    oof_pred = np.average(oof_pred, axis=0)\n",
    "    \n",
    "    seed_log_loss = mean_log_loss(train_targets.values, oof_pred)\n",
    "    print(f'Our out of folds log loss for our seed blend model is {seed_log_loss}')\n",
    "    \n",
    "    return test_pred, oof_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T15:13:11.089706Z",
     "iopub.status.busy": "2020-11-30T15:13:11.068726Z",
     "iopub.status.idle": "2020-11-30T15:13:11.097705Z",
     "shell.execute_reply": "2020-11-30T15:13:11.097193Z"
    },
    "papermill": {
     "duration": 0.062186,
     "end_time": "2020-11-30T15:13:11.097812",
     "exception": false,
     "start_time": "2020-11-30T15:13:11.035626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Got this predictors from public kernels for the resnet type model\n",
    "start_predictors = [\"g-0\", \"g-7\", \"g-8\", \"g-10\", \"g-13\", \"g-17\", \"g-20\", \"g-22\", \"g-24\", \"g-26\", \"g-28\", \"g-29\", \"g-30\", \"g-31\", \"g-32\", \"g-34\", \"g-35\", \"g-36\", \"g-37\", \"g-38\",\n",
    "                    \"g-39\",\"g-41\", \"g-46\", \"g-48\", \"g-50\", \"g-51\", \"g-52\", \"g-55\", \"g-58\", \"g-59\", \"g-61\", \"g-62\", \"g-63\", \"g-65\", \"g-66\", \"g-67\", \"g-68\", \"g-70\", \"g-72\", \"g-74\", \n",
    "                    \"g-75\", \"g-79\", \"g-83\", \"g-84\", \"g-85\", \"g-86\", \"g-90\", \"g-91\", \"g-94\", \"g-95\", \"g-96\", \"g-97\", \"g-98\", \"g-100\", \"g-102\", \"g-105\", \"g-106\", \"g-112\", \"g-113\", \n",
    "                    \"g-114\", \"g-116\", \"g-121\", \"g-123\", \"g-126\", \"g-128\", \"g-131\", \"g-132\", \"g-134\", \"g-135\", \"g-138\", \"g-139\", \"g-140\", \"g-142\", \"g-144\", \"g-145\", \"g-146\", \n",
    "                    \"g-147\", \"g-148\", \"g-152\", \"g-155\", \"g-157\", \"g-158\", \"g-160\", \"g-163\", \"g-164\", \"g-165\", \"g-170\", \"g-173\", \"g-174\", \"g-175\", \"g-177\", \"g-178\", \"g-181\", \n",
    "                    \"g-183\", \"g-185\", \"g-186\", \"g-189\", \"g-192\", \"g-194\", \"g-195\", \"g-196\", \"g-197\", \"g-199\", \"g-201\", \"g-202\", \"g-206\", \"g-208\", \"g-210\", \"g-213\", \"g-214\", \n",
    "                    \"g-215\", \"g-220\", \"g-226\", \"g-228\", \"g-229\", \"g-235\", \"g-238\", \"g-241\", \"g-242\", \"g-243\", \"g-244\", \"g-245\", \"g-248\", \"g-250\", \"g-251\", \"g-254\", \"g-257\", \n",
    "                    \"g-259\", \"g-261\", \"g-266\", \"g-270\", \"g-271\", \"g-272\", \"g-275\", \"g-278\", \"g-282\", \"g-287\", \"g-288\", \"g-289\", \"g-291\", \"g-293\", \"g-294\", \"g-297\", \"g-298\",\n",
    "                    \"g-301\", \"g-303\", \"g-304\", \"g-306\", \"g-308\", \"g-309\", \"g-310\", \"g-311\", \"g-314\", \"g-315\", \"g-316\", \"g-317\", \"g-320\", \"g-321\", \"g-322\", \"g-327\", \"g-328\", \n",
    "                    \"g-329\", \"g-332\", \"g-334\", \"g-335\", \"g-336\", \"g-337\", \"g-339\", \"g-342\", \"g-344\", \"g-349\", \"g-350\", \"g-351\", \"g-353\", \"g-354\", \"g-355\", \"g-357\", \"g-359\", \n",
    "                    \"g-360\", \"g-364\", \"g-365\", \"g-366\", \"g-367\", \"g-368\", \"g-369\", \"g-374\", \"g-375\", \"g-377\", \"g-379\", \"g-385\", \"g-386\", \"g-390\", \"g-392\", \"g-393\", \"g-400\", \n",
    "                    \"g-402\", \"g-406\", \"g-407\", \"g-409\", \"g-410\", \"g-411\", \"g-414\", \"g-417\", \"g-418\", \"g-421\", \"g-423\", \"g-424\", \"g-427\", \"g-429\", \"g-431\", \"g-432\", \"g-433\", \n",
    "                    \"g-434\", \"g-437\", \"g-439\", \"g-440\", \"g-443\", \"g-449\", \"g-458\", \"g-459\", \"g-460\", \"g-461\", \"g-464\", \"g-467\", \"g-468\", \"g-470\", \"g-473\", \"g-477\", \"g-478\", \n",
    "                    \"g-479\", \"g-484\", \"g-485\", \"g-486\", \"g-488\", \"g-489\", \"g-491\", \"g-494\", \"g-496\", \"g-498\", \"g-500\", \"g-503\", \"g-504\", \"g-506\", \"g-508\", \"g-509\", \"g-512\", \n",
    "                    \"g-522\", \"g-529\", \"g-531\", \"g-534\", \"g-539\", \"g-541\", \"g-546\", \"g-551\", \"g-553\", \"g-554\", \"g-559\", \"g-561\", \"g-562\", \"g-565\", \"g-568\", \"g-569\", \"g-574\", \n",
    "                    \"g-577\", \"g-578\", \"g-586\", \"g-588\", \"g-590\", \"g-594\", \"g-595\", \"g-596\", \"g-597\", \"g-599\", \"g-600\", \"g-603\", \"g-607\", \"g-615\", \"g-618\", \"g-619\", \"g-620\", \n",
    "                    \"g-625\", \"g-628\", \"g-629\", \"g-632\", \"g-634\", \"g-635\", \"g-636\", \"g-638\", \"g-639\", \"g-641\", \"g-643\", \"g-644\", \"g-645\", \"g-646\", \"g-647\", \"g-648\", \"g-663\", \n",
    "                    \"g-664\", \"g-665\", \"g-668\", \"g-669\", \"g-670\", \"g-671\", \"g-672\", \"g-673\", \"g-674\", \"g-677\", \"g-678\", \"g-680\", \"g-683\", \"g-689\", \"g-691\", \"g-693\", \"g-695\", \n",
    "                    \"g-701\", \"g-702\", \"g-703\", \"g-704\", \"g-705\", \"g-706\", \"g-708\", \"g-711\", \"g-712\", \"g-720\", \"g-721\", \"g-723\", \"g-724\", \"g-726\", \"g-728\", \"g-731\", \"g-733\", \n",
    "                    \"g-738\", \"g-739\", \"g-742\", \"g-743\", \"g-744\", \"g-745\", \"g-749\", \"g-750\", \"g-752\", \"g-760\", \"g-761\", \"g-764\", \"g-766\", \"g-768\", \"g-770\", \"g-771\", \"c-0\", \n",
    "                    \"c-1\", \"c-2\", \"c-3\", \"c-4\", \"c-5\", \"c-6\", \"c-7\", \"c-8\", \"c-9\", \"c-10\", \"c-11\", \"c-12\", \"c-13\", \"c-14\", \"c-15\", \"c-16\", \"c-17\", \"c-18\", \"c-19\", \"c-20\", \n",
    "                    \"c-21\", \"c-22\", \"c-23\", \"c-24\", \"c-25\", \"c-26\", \"c-27\", \"c-28\", \"c-29\", \"c-30\", \"c-31\", \"c-32\", \"c-33\", \"c-34\", \"c-35\", \"c-36\", \"c-37\", \"c-38\", \"c-39\", \n",
    "                    \"c-40\", \"c-41\", \"c-42\", \"c-43\", \"c-44\", \"c-45\", \"c-46\", \"c-47\", \"c-48\", \"c-49\", \"c-50\", \"c-51\", \"c-52\", \"c-53\", \"c-54\", \"c-55\", \"c-56\", \"c-57\", \"c-58\", \n",
    "                    \"c-59\", \"c-60\", \"c-61\", \"c-62\", \"c-63\", \"c-64\", \"c-65\", \"c-66\", \"c-67\", \"c-68\", \"c-69\", \"c-70\", \"c-71\", \"c-72\", \"c-73\", \"c-74\", \"c-75\", \"c-76\", \"c-77\", \n",
    "                    \"c-78\", \"c-79\", \"c-80\", \"c-81\", \"c-82\", \"c-83\", \"c-84\", \"c-85\", \"c-86\", \"c-87\", \"c-88\", \"c-89\", \"c-90\", \"c-91\", \"c-92\", \"c-93\", \"c-94\", \"c-95\", \"c-96\", \n",
    "                    \"c-97\", \"c-98\", \"c-99\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T15:13:11.151986Z",
     "iopub.status.busy": "2020-11-30T15:13:11.151179Z",
     "iopub.status.idle": "2020-11-30T15:13:11.155084Z",
     "shell.execute_reply": "2020-11-30T15:13:11.154542Z"
    },
    "papermill": {
     "duration": 0.033307,
     "end_time": "2020-11-30T15:13:11.155186",
     "exception": false,
     "start_time": "2020-11-30T15:13:11.121879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def submission(test_pred):\n",
    "    sample_submission.loc[:, train_targets.columns] = test_pred\n",
    "    sample_submission.loc[test['cp_type'] == 1, train_targets.columns] = 0 \n",
    "    sample_submission.to_csv('submission.csv', index=False)\n",
    "    return sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T15:13:11.212731Z",
     "iopub.status.busy": "2020-11-30T15:13:11.211988Z",
     "iopub.status.idle": "2020-11-30T15:13:17.540595Z",
     "shell.execute_reply": "2020-11-30T15:13:17.539469Z"
    },
    "papermill": {
     "duration": 6.360916,
     "end_time": "2020-11-30T15:13:17.540719",
     "exception": false,
     "start_time": "2020-11-30T15:13:11.179803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## load data\n",
    "train = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\n",
    "train_targets = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\n",
    "test = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\n",
    "original_cols = train.columns.values\n",
    "sample_submission = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T15:13:17.598124Z",
     "iopub.status.busy": "2020-11-30T15:13:17.597457Z",
     "iopub.status.idle": "2020-11-30T15:13:37.267933Z",
     "shell.execute_reply": "2020-11-30T15:13:37.267345Z"
    },
    "papermill": {
     "duration": 19.704312,
     "end_time": "2020-11-30T15:13:37.268088",
     "exception": false,
     "start_time": "2020-11-30T15:13:17.563776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## encoding categorical variables\n",
    "train, train_targets, test = mapping_and_filter(train, train_targets, test)\n",
    "## numerical feature engineering\n",
    "train, test = fe_stats(train, test)\n",
    "train, test = c_squared(train, test)\n",
    "train, test = fe_pca(train, test, n_components_g = 70, n_components_c = 10, SEED = 123)\n",
    "train, test, features = scaling(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T15:13:37.321930Z",
     "iopub.status.busy": "2020-11-30T15:13:37.321178Z",
     "iopub.status.idle": "2020-11-30T15:13:37.324493Z",
     "shell.execute_reply": "2020-11-30T15:13:37.324986Z"
    },
    "papermill": {
     "duration": 0.033128,
     "end_time": "2020-11-30T15:13:37.325116",
     "exception": false,
     "start_time": "2020-11-30T15:13:37.291988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cp_time', 'cp_dose', 'g-0', 'g-1', 'g-2', 'g-3', 'g-4', 'g-5', 'g-6',\n",
       "       'g-7',\n",
       "       ...\n",
       "       'pca_c1', 'pca_c2', 'pca_c3', 'pca_c4', 'pca_c5', 'pca_c6', 'pca_c7',\n",
       "       'pca_c8', 'pca_c9', 'pca_c10'],\n",
       "      dtype='object', length=1069)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T15:13:37.381958Z",
     "iopub.status.busy": "2020-11-30T15:13:37.380077Z",
     "iopub.status.idle": "2020-11-30T15:13:37.382690Z",
     "shell.execute_reply": "2020-11-30T15:13:37.383176Z"
    },
    "papermill": {
     "duration": 0.034372,
     "end_time": "2020-11-30T15:13:37.383291",
     "exception": false,
     "start_time": "2020-11-30T15:13:37.348919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Seed for deterministic results\n",
    "# Seed for deterministic results\n",
    "SEEDS1 = [1, 2, 3, 4, 5, 6, 7]\n",
    "SEEDS2 = [8, 9, 10, 11, 12, 13, 14]\n",
    "SEEDS3 = [15, 16, 17, 18, 19, 20, 21]\n",
    "SEEDS4 = [22, 23, 24, 25, 26, 27, 28]\n",
    "SEEDS5 = [29, 30, 31, 32, 33, 34, 35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T15:13:37.440894Z",
     "iopub.status.busy": "2020-11-30T15:13:37.439378Z",
     "iopub.status.idle": "2020-11-30T15:22:59.165880Z",
     "shell.execute_reply": "2020-11-30T15:22:59.165241Z"
    },
    "papermill": {
     "duration": 561.759301,
     "end_time": "2020-11-30T15:22:59.166025",
     "exception": false,
     "start_time": "2020-11-30T15:13:37.406724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model 5l with seed 29 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.016779216297852038\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model 5l with seed 30 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.016892926040674834\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model 5l with seed 31 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.01681561217120392\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model 5l with seed 32 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.016900396532058926\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model 5l with seed 33 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.01677089344625973\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model 5l with seed 34 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.016843859345616764\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model 5l with seed 35 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.01686120163194982\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Our out of folds log loss for our seed blend model is 0.016109421768563885\n",
      "Using model 4l with seed 22 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.01669970610087885\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model 4l with seed 23 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.01663989447522416\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model 4l with seed 24 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.01673677197815805\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model 4l with seed 25 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.01674847917837259\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model 4l with seed 26 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.01670834197654444\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model 4l with seed 27 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.016705949920498946\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model 4l with seed 28 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.016770371780466562\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Our out of folds log loss for our seed blend model is 0.016015784507114116\n",
      "Using model 3l with seed 15 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.01676807102182332\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model 3l with seed 16 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.016747119827261396\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model 3l with seed 17 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.016767056416124484\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model 3l with seed 18 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.016658292219233706\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model 3l with seed 19 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.01667825282578825\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model 3l with seed 20 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.016691878777214415\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model 3l with seed 21 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.01677329017080852\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Our out of folds log loss for our seed blend model is 0.01585904706845748\n",
      "Using model 2l with seed 8 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.016427616801008384\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model 2l with seed 9 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.016407402952464942\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model 2l with seed 10 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.016488337095880684\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model 2l with seed 11 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.016398902112545344\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model 2l with seed 12 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.016464631212911803\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model 2l with seed 13 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.016414221858077484\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model 2l with seed 14 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.01644782423494588\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Our out of folds log loss for our seed blend model is 0.01590956400712374\n",
      "Using model rs with seed 1 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.018483410998601298\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model rs with seed 2 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.018683777026237955\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model rs with seed 3 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.018358442961966585\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model rs with seed 4 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.01844580479273813\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model rs with seed 5 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.018764787675035175\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model rs with seed 6 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.018739540009148663\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Using model rs with seed 7 for inference\n",
      "Trained with 1069 features\n",
      "Our out of folds mean log loss score is 0.018591199252074746\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Our out of folds log loss for our seed blend model is 0.01621926288461257\n"
     ]
    }
   ],
   "source": [
    "# Inference time\n",
    "test_pred_5l, oof_pred_5l = run_multiple_seeds(train, test, train_targets, features, start_predictors, SEEDS=SEEDS5, MODEL = '5l')\n",
    "test_pred_4l, oof_pred_4l = run_multiple_seeds(train, test, train_targets, features, start_predictors, SEEDS=SEEDS4, MODEL = '4l')\n",
    "test_pred_3l, oof_pred_3l = run_multiple_seeds(train, test, train_targets, features, start_predictors, SEEDS=SEEDS3, MODEL = '3l')\n",
    "test_pred_2l, oof_pred_2l = run_multiple_seeds(train, test, train_targets, features, start_predictors, SEEDS=SEEDS2, MODEL = '2l')\n",
    "test_pred_rs, oof_pred_rs = run_multiple_seeds(train, test, train_targets, features, start_predictors, SEEDS=SEEDS1, MODEL = 'rs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-30T15:22:59.248651Z",
     "iopub.status.busy": "2020-11-30T15:22:59.247309Z",
     "iopub.status.idle": "2020-11-30T15:23:03.486217Z",
     "shell.execute_reply": "2020-11-30T15:23:03.485291Z"
    },
    "papermill": {
     "duration": 4.283323,
     "end_time": "2020-11-30T15:23:03.486332",
     "exception": false,
     "start_time": "2020-11-30T15:22:59.203009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our final out of folds log loss for our classic dnn blend is 0.015740965244900377\n",
      "Our final out of folds log loss for our classic dnn + dnn resnet type model is 0.01569524242679387\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>0.014640</td>\n",
       "      <td>0.017488</td>\n",
       "      <td>0.003493</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.004725</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.002636</td>\n",
       "      <td>0.006791</td>\n",
       "      <td>0.001702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.015672</td>\n",
       "      <td>0.012004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.007453</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.004235</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.002959</td>\n",
       "      <td>0.006311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.008976</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>0.001868</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.013028</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.005572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>0.004422</td>\n",
       "      <td>0.015479</td>\n",
       "      <td>0.024378</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.007890</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0  id_0004d9e33                     0.001112                0.001786   \n",
       "1  id_001897cda                     0.000276                0.001171   \n",
       "2  id_002429b5b                     0.000000                0.000000   \n",
       "3  id_00276f245                     0.000759                0.000944   \n",
       "4  id_0027f1083                     0.001976                0.001377   \n",
       "\n",
       "   acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0        0.001904                        0.014640   \n",
       "1        0.001963                        0.002234   \n",
       "2        0.000000                        0.000000   \n",
       "3        0.002009                        0.008976   \n",
       "4        0.004422                        0.015479   \n",
       "\n",
       "   acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                           0.017488                        0.003493   \n",
       "1                           0.000941                        0.002514   \n",
       "2                           0.000000                        0.000000   \n",
       "3                           0.005243                        0.004972   \n",
       "4                           0.024378                        0.001400   \n",
       "\n",
       "   adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                    0.001534                       0.004725   \n",
       "1                    0.003945                       0.015672   \n",
       "2                    0.000000                       0.000000   \n",
       "3                    0.001868                       0.001799   \n",
       "4                    0.007890                       0.001354   \n",
       "\n",
       "   adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                    0.000378  ...                               0.001518   \n",
       "1                    0.012004  ...                               0.001258   \n",
       "2                    0.000000  ...                               0.000000   \n",
       "3                    0.000550  ...                               0.000982   \n",
       "4                    0.000743  ...                               0.001555   \n",
       "\n",
       "   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0      0.002703         0.002553           0.000870   \n",
       "1      0.000654         0.007453           0.000149   \n",
       "2      0.000000         0.000000           0.000000   \n",
       "3      0.000619         0.002897           0.013028   \n",
       "4      0.000807         0.005074           0.001661   \n",
       "\n",
       "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                   0.000344                               0.001601   \n",
       "1                   0.004235                               0.001029   \n",
       "2                   0.000000                               0.000000   \n",
       "3                   0.004356                               0.000913   \n",
       "4                   0.000782                               0.001552   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0         0.000589   0.002636                    0.006791       0.001702  \n",
       "1         0.000916   0.000765                    0.002959       0.006311  \n",
       "2         0.000000   0.000000                    0.000000       0.000000  \n",
       "3         0.000935   0.002114                    0.001004       0.005572  \n",
       "4         0.002706   0.002333                    0.000199       0.000989  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Blend 5l, 4l, 3l and l2 dnn model\n",
    "oof_pred = np.average([oof_pred_5l, oof_pred_4l, oof_pred_3l, oof_pred_2l], axis = 0)\n",
    "seed_log_loss = mean_log_loss(train_targets.values, oof_pred)\n",
    "print(f'Our final out of folds log loss for our classic dnn blend is {seed_log_loss}')\n",
    "test_pred = np.average([test_pred_5l, test_pred_4l, test_pred_3l, test_pred_2l], axis = 0)\n",
    "\n",
    "# Blend the result of the previous model with the dnn resnet type model\n",
    "oof_pred = np.average([oof_pred, oof_pred_rs], axis = 0)\n",
    "seed_log_loss = mean_log_loss(train_targets.values, oof_pred)\n",
    "print(f'Our final out of folds log loss for our classic dnn + dnn resnet type model is {seed_log_loss}')\n",
    "test_pred = np.average([test_pred, test_pred_rs], axis = 0)\n",
    "\n",
    "sample_submission = submission(test_pred)\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.037855,
     "end_time": "2020-11-30T15:23:03.562771",
     "exception": false,
     "start_time": "2020-11-30T15:23:03.524916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 606.096807,
   "end_time": "2020-11-30T15:23:04.738136",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-30T15:12:58.641329",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
